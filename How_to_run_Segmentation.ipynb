{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1b77f-c468-4277-a5ea-1566a154b0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f83404-5a10-4789-b106-79ec9c191d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a01ab27-ad31-4d2a-a53d-4c9a229a9d6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. This modolue is to figure out how to run the segmentation for the video and laod the packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df684f9-515e-4d66-aee6-6befceb00632",
   "metadata": {},
   "source": [
    "1. pip install stardist: https://pypi.org/project/stardist/\n",
    "2. pip install tensorflow: https://www.tensorflow.org/install/pip\n",
    "3. please be noted to install the specify tensorflow and pytorch version that work with the same compatible cuda\n",
    "4. This code will take memory to save the segmented volumne for each frame as h5 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564ca9c6-2236-41dc-8063-6b0e2e3669f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 22:40:51.191259: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla P100-PCIE-12GB\n",
      "True\n",
      "2.13.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# from Segmentation import *\n",
    "from Segmentation.Video_seg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828084c8-f213-430a-a3b2-97de04c75d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b4394-6b0a-4409-9dce-fe4e56bffceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c89efcda-538d-4ad2-949a-a453c57ea00c",
   "metadata": {},
   "source": [
    "#### 2. Load the model for 3D segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d205e09-2673-4c84-9892-d70024ff16d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "base_model.py (149): output path for model already exists, files may be overwritten: /work/venkatachalamlab/Hang/GNN_matching_git/code/GNN_match/models/stardist\n",
      "2024-03-27 22:41:07.918258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11437 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:03:00.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default values: prob_thresh=0.5, nms_thresh=0.4.\n",
      "There are 4 registered models for 'StarDist2D':\n",
      "\n",
      "Name                  Alias(es)\n",
      "────                  ─────────\n",
      "'2D_versatile_fluo'   'Versatile (fluorescent nuclei)'\n",
      "'2D_versatile_he'     'Versatile (H&E nuclei)'\n",
      "'2D_paper_dsb2018'    'DSB 2018 (from StarDist 2D paper)'\n",
      "'2D_demo'             None\n",
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "model_weights_path = '/work/venkatachalamlab/Hang/GNN_matching_git/code/GNN_match/Segmentation/model_weights/weights_best_42stacks_all.h5'\n",
    "model, model_2D = load_model_3D_and_2D(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b62931-55b0-418a-9fdd-7bc4563d77a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce955bd4-0156-49c6-b0b8-375111cf99ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be205e2a-3fd9-46d4-b067-f47bdb42803b",
   "metadata": {},
   "source": [
    "#### 3. Run Segmentation for the video and Please specify the arguments: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9ad7e0-40d4-4b41-b54c-3e62a975945c",
   "metadata": {},
   "source": [
    "'load_path': the folder to load the original h5 file \\\n",
    "'save_folder: the folder to save segmentation file  \\\n",
    "'ch: the channel index used for tracking \\\n",
    "'zoom_factor': for low resolution zoom_factor = 2, staticfluild use zoom_factor = 1 \\\n",
    "'start_idx': the starting time index \\\n",
    "'end_idx': the ending time index \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65481e77-372d-44c1-a746-cced8df3788a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c30c363-b2ee-43d1-a766-a9cd401159e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_folder = '/work/venkatachalamlab/Hang/GNN_matching_git/dataset/ZM9624/'\n",
    "save_folder = 'seg'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a8eeef-7bb8-4fa3-bb69-de870e995b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:43<00:00, 21.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish the segmentation of movie in the folder path:  seg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_shape = get_img_shape(load_folder)\n",
    "[ch, zoom_factor] = [1,2]\n",
    "for t_idx in tqdm(range(img_shape[0])):\n",
    "# for t_idx in tqdm(range(2)):\n",
    "    label_z = get_frame_segmentation(model,model_2D,t_idx, ch, zoom_factor,load_folder)\n",
    "    # label[t_idx,0] = label_z\n",
    "    save_var_h5('seg/'+str(t_idx)+'.h5',[label_z],['label'])\n",
    "print(\"finish the segmentation of movie in the folder path: \", save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fc1c47c-dfd6-440f-b5f6-166fc648389f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f584701-eab4-47cb-a394-36fd4f349bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac19836-2e82-42b2-bc8d-bd74851fc79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7249a3a-cab8-43ed-85bf-52a88739ceb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82f37a1e-a4c9-48ca-947e-0e6a9a58f9a5",
   "metadata": {},
   "source": [
    "#### 4. The following version could run the above in parallel, needs to specify the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9970880e-ccbb-4dd1-8119-db19ae31be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Define the range of iterations you want to process in parallel\n",
    "#     img_shape = get_img_shape(load_folder)\n",
    "#     [ch, zoom_factor] = [1,2] ## (for low resolution zoom_factor = 2, staticfluild use zoom_factor = 1)\n",
    "#     start_idx = 0  ## starting time index\n",
    "#     # end_idx = img_shape[0]   ## end time index\n",
    "#     end_idx = 2   \n",
    "\n",
    "#     # Create a ThreadPoolExecutor for parallel processing\n",
    "#     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#         # Use partial to create a function with fixed arguments (img_shape, model, model_2D, ch, zoom_factor, save_folder)\n",
    "#         process_partial = partial(process_iteration,  model=model, model_2D=model_2D, ch=ch, zoom_factor=zoom_factor, \n",
    "#                                   load_folder=load_folder, save_folder=save_folder)\n",
    "\n",
    "#         # Iterate and process in parallel using the ThreadPoolExecutor\n",
    "#         tqdm_parallel = tqdm(range(start_idx, end_idx, 1))\n",
    "#         # tqdm_parallel = tqdm(not_exits)\n",
    "#         results = list(executor.map(process_partial, tqdm_parallel))\n",
    "\n",
    "#     # Print the results (t_idx values)\n",
    "#     print(\"Processed t_idx values:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8daadf5-15b0-40f8-bef8-a19c7fa9a9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
